{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook focuses on testing an xgboost model without resorting to feature selection or dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sousa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sousa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sousa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from re import sub\n",
    "from decimal import Decimal\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from math import sqrt\n",
    "import tests as t\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import folium\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import xgboost as xgb\n",
    "pd.set_option('display.max_columns', 106)\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "porto = pd.read_csv(r\"C:\\Users\\sousa\\Desktop\\github\\Airbnb Tale of 2 cities\\Data Portugal\\porto_listings.csv\")\n",
    "lisbon = pd.read_csv(r\"C:\\Users\\sousa\\Desktop\\github\\Airbnb Tale of 2 cities\\Data Portugal\\lisbon_listings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_porto = porto.drop('price', 1)\n",
    "y_porto = porto['price']\n",
    "\n",
    "X_lisbon = lisbon.drop('price', 1)\n",
    "y_lisbon = lisbon['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split our data\n",
    "X_porto_train, X_porto_test, y_porto_train, y_porto_test = train_test_split(X_porto, y_porto, test_size=0.2)\n",
    "\n",
    "X_lisbon_train, X_lisbon_test, y_lisbon_train, y_lisbon_test = train_test_split(X_lisbon, y_lisbon, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the data\n",
    "sc = StandardScaler()\n",
    "X_porto_train = sc.fit_transform(X_porto_train)\n",
    "X_porto_test  = sc.transform(X_porto_test)\n",
    "\n",
    "X_lisbon_train = sc.fit_transform(X_lisbon_train)\n",
    "X_lisbon_test  = sc.transform(X_lisbon_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Model: XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = xgb.XGBRegressor()\n",
    "\n",
    "param_grid = {'n_estimators': [100, 200, 300, 400],\n",
    "              'learning_rate': [0.01, 0.05, 0.1], \n",
    "              'max_depth': [3, 4, 5, 6, 7],\n",
    "              'colsample_bytree': [0.6, 0.7, 1],\n",
    "              'gamma': [0.0, 0.1, 0.2]}\n",
    "\n",
    "booster_grid_search = GridSearchCV(booster, param_grid, cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:15:44] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "{'colsample_bytree': 0.6, 'gamma': 0.0, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "# train the tuned random forest porto\n",
    "booster_grid_search.fit(X_porto_train, y_porto_train)\n",
    "\n",
    "print(booster_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:45:58] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "{'colsample_bytree': 0.6, 'gamma': 0.1, 'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "# train the tuned random forest lisbon\n",
    "booster_grid_search.fit(X_lisbon_train, y_lisbon_train)\n",
    "\n",
    "print(booster_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating the models based on the hyperparameters found by grid search\n",
    "booster_porto = xgb.XGBRegressor(colsample_bytree=0.6, gamma=0.0, learning_rate=0.1, \n",
    "                           max_depth=7, n_estimators=200, random_state=4)\n",
    "\n",
    "booster_lisbon = xgb.XGBRegressor(colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, \n",
    "                           max_depth=7, n_estimators=200, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:30:40] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:31:01] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.7, gamma=0.2,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=7, min_child_weight=1, missing=None, n_estimators=200,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=4,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training\n",
    "booster_porto.fit(X_porto_train, y_porto_train)\n",
    "\n",
    "booster_lisbon.fit(X_lisbon_train, y_lisbon_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "y_pred_train_porto = booster_porto.predict(X_porto_train)\n",
    "y_pred_test_porto = booster_porto.predict(X_porto_test)\n",
    "\n",
    "y_pred_train_lisbon = booster_lisbon.predict(X_lisbon_train)\n",
    "y_pred_test_lisbon = booster_lisbon.predict(X_lisbon_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_porto: 37.5776\n",
      "RMSE_lisbon: 43.4376\n",
      "MSE_porto: 1412.079\n",
      "MSE_lisbon: 1886.8287\n",
      "r2_porto: 0.4858\n",
      "r2_lisbon: 0.6729\n"
     ]
    }
   ],
   "source": [
    "#metrics to determine quality of model\n",
    "RMSE_porto = np.sqrt(mean_squared_error(y_porto_test, y_pred_test_porto))\n",
    "RMSE_lisbon = np.sqrt(mean_squared_error(y_lisbon_test, y_pred_test_lisbon))\n",
    "\n",
    "MSE_porto = mean_squared_error(y_porto_test, y_pred_test_porto)\n",
    "MSE_lisbon = mean_squared_error(y_lisbon_test, y_pred_test_lisbon)\n",
    "\n",
    "r2_porto = r2_score(y_porto_test, y_pred_test_porto)\n",
    "r2_lisbon = r2_score(y_lisbon_test, y_pred_test_lisbon)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"RMSE_porto: {round(RMSE_porto, 4)}\")\n",
    "print(f\"RMSE_lisbon: {round(RMSE_lisbon, 4)}\")\n",
    "\n",
    "print(f\"MSE_porto: {round(MSE_porto, 4)}\")\n",
    "print(f\"MSE_lisbon: {round(MSE_lisbon, 4)}\")\n",
    "\n",
    "print(f\"r2_porto: {round(r2_porto, 4)}\")\n",
    "print(f\"r2_lisbon: {round(r2_lisbon, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
